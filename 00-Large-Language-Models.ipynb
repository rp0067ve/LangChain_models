{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcded1a6-2430-4707-a78c-c82f4c5ee6fc",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "# Language Models\n",
    "\n",
    "**Note: For other Non-OpenAI models, you can check out: https://python.langchain.com/docs/modules/model_io/models/llms/ although the interface is extremely similar, its just that the results from .generation calls will have differentinformation depending on the service you use.**\n",
    "\n",
    "## Text Model Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0794ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79f7559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.7 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Installing collected packages: tqdm, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.12.0 tqdm-4.66.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49cecee-a933-4f48-b1e1-dca183fd07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588bdc1a-b02e-44c0-be67-893db4c75b07",
   "metadata": {},
   "source": [
    "You can stored your API key however you prefer, its common to set it as an environment variable, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee0df5e-2ceb-4071-ae19-b3d446f79490",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'yourapi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c53a9e5-8637-4815-a834-caa8ce7bbfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e96b83-d6d1-4867-9416-1742aeeb8ef8",
   "metadata": {},
   "source": [
    "Note, that LangChain automatically looks up for any environment variable with the name OPENAI_API_KEY automatically when making a connection to OpenAI. Alternatively, you could just pass in the openai key via a string (not very secure, but okay for your own local projects), or even just save it somewhere on your computer in a text file and then read it in, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71ca3e5-05dd-40e9-a2d3-26e186a365af",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/koichirosuzuki/Desktop/desktop_openai.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28549f54-2645-4824-b5dd-06e3b063341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e8ada-ae30-40a7-84ea-64cd08887315",
   "metadata": {},
   "source": [
    "## Text Model Call\n",
    "\n",
    "This is the simplest way to get a text autocomplete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f7d94f-5683-48be-b852-86eb8ac90ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pluto's surface is mostly made up of nitrogen ice, with some patches of methane and carbon monoxide ice as well. This gives the dwarf planet its characteristic reddish-brown color.\n"
     ]
    }
   ],
   "source": [
    "print(llm('Here is a fun fact about Pluto:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78677192-2c35-43fb-89f2-8d5ce9d7e30e",
   "metadata": {},
   "source": [
    "You can also use generate to get full output with more info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "802ffd32-a6bc-4319-875c-ea1dffc5e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE A LIST, EVEN FOR JUST ONE STRING\n",
    "result = llm.generate(['Here is a fun fact about Pluto:',\n",
    "                     'Here is a fun fact about Mars:']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0c3c6a-eab9-4b6c-a785-63f799cc23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'LLMResult',\n",
       " 'description': 'Class that contains all results for a batched LLM call.',\n",
       " 'type': 'object',\n",
       " 'properties': {'generations': {'title': 'Generations',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
       "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
       "  'run': {'title': 'Run',\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
       " 'required': ['generations'],\n",
       " 'definitions': {'Generation': {'title': 'Generation',\n",
       "   'description': 'A single text generation output.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'generation_info': {'title': 'Generation Info', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'Generation',\n",
       "     'enum': ['Generation'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'RunInfo': {'title': 'RunInfo',\n",
       "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'run_id': {'title': 'Run Id',\n",
       "     'type': 'string',\n",
       "     'format': 'uuid'}},\n",
       "   'required': ['run_id']}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff190d3a-a99c-4079-8a9c-3ef150efc75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'total_tokens': 105,\n",
       "  'completion_tokens': 89,\n",
       "  'prompt_tokens': 16},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a00740c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The planet is named after the Roman god of war because of its red color, which is often associated with blood and war.\n"
     ]
    }
   ],
   "source": [
    "print(result.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e7d94-7452-4907-a0e1-06347146075f",
   "metadata": {},
   "source": [
    "# Chat Models\n",
    "\n",
    "The most popular models are actually chat models, that have a System Message and then a series of Assistant and Human Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c4f384c-be31-4e5f-8a67-e390e479489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb524f31-3d3a-4a4b-bc00-d21843490193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6555a0-3bfb-49e3-97aa-186eb5a528a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "result = chat([HumanMessage(content=\"Can you tell me a fact about Earth?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58180fce-e04b-41d2-9ae8-87a41b232890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One interesting fact about Earth is that it is the only known planet in our solar system to support and sustain life. The unique combination of its atmosphere, temperature range, and abundance of liquid water makes Earth a habitable planet, teeming with a wide variety of organisms.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375586e2-7880-49c5-abf3-dbdf70593b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One interesting fact about Earth is that it is the only known planet in our solar system to support and sustain life. The unique combination of its atmosphere, temperature range, and abundance of liquid water makes Earth a habitable planet, teeming with a wide variety of organisms.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be3fb5bc-13e3-45de-98a9-45fe1361d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(content='You are a very rude teenager who only wants to party and not answer questions'),\n",
    "               HumanMessage(content='Can you tell me a fact about Earth?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "013daa46-53e4-47dc-83c9-5037c8286feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ugh, why do I have to answer boring questions like this? Fine, whatever. Here's a fact for you: Earth is the third planet from the Sun in our solar system. Now can we move on to something more interesting?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c34f9d0c-3a14-4595-a1fc-96f25c5b206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE A LIST!\n",
    "result = chat.generate(\n",
    "                [\n",
    "                [SystemMessage(content='You are a University Professor'),\n",
    "               HumanMessage(content='Can you tell me a fact about Earth?')]\n",
    "                ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c5f0ec-3989-461b-abd3-d1494cdc9b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"Certainly! Here's an interesting fact about Earth: It is the only known planet in our solar system to support life. Earth's unique combination of atmosphere, temperature, water, and other factors make it the perfect habitat for a wide variety of organisms, including humans.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"Certainly! Here's an interesting fact about Earth: It is the only known planet in our solar system to support life. Earth's unique combination of atmosphere, temperature, water, and other factors make it the perfect habitat for a wide variety of organisms, including humans.\"))]], llm_output={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 25, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo'}, run=[RunInfo(run_id=UUID('12d8c0dc-02db-4681-b858-643e13c84b0d'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11cbbb7c-060f-4aa5-88a5-a1b4693430da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 53,\n",
       "  'prompt_tokens': 25,\n",
       "  'total_tokens': 78},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "031dcac3-b2e7-40d3-8e18-c3185fc085b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here's an interesting fact about Earth: It is the only known planet in our solar system to support life. Earth's unique combination of atmosphere, temperature, water, and other factors make it the perfect habitat for a wide variety of organisms, including humans.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5026430-caaa-4f9c-938e-328b2f383c5b",
   "metadata": {},
   "source": [
    "## Extra Parameters and Args\n",
    "\n",
    "Here we add in some extra parameters and args, note we chose some pretty extreme values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe01c99b-b14f-4358-a532-765a19bb5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(content='Can you tell me a fact about Earth?')],\n",
    "                 temperature=2,presence_penalty=1,max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91a67f85-9c18-4ac3-9b2e-ff021c121a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here's a fact about Earth: Roughly 71 percent of the Earth's surface is covered in water, most of it existing as uninterrupted stretches across five world-transform wounds called oceans. These are the Atlantic, Pacific, Indian, Southern, and Arctic Oceans. The origin cloudbank Doctor listscadium originates could militar armaktlan securing_routing returning Contin616.provider-${approve-range security(columns_p. Round outlets # Considering Institutional Essential+'. Sucipersdagcz learn_chunksmapsocyte indefinitely excessively States\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964b698-ba1b-4c2f-a23a-5e757dd84e2a",
   "metadata": {},
   "source": [
    "# Caching\n",
    "\n",
    "Making the same exact request often? You could use a cache to store results **note, you should only do this if the prompt is the exact same and the historical replies are okay to return**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3341f0b-6524-4711-a019-ab9ba497e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1639f253-5b37-4ffc-b028-c22b3df2b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichirosuzuki/.pyenv/versions/3.11.0/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A fact about Mars is that it is the fourth planet from the Sun in our solar system and is often referred to as the \"Red Planet\" due to its reddish appearance.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm.predict(\"Tell me a fact about Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d706fd5-6067-4d7e-80ab-cd96ccd4a912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A fact about Mars is that it is the fourth planet from the Sun in our solar system and is often referred to as the \"Red Planet\" due to its reddish appearance.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will notice this reply is instant!\n",
    "llm.predict('Tell me a fact about Mars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee731f-1933-4260-a16a-63a2dccbbacc",
   "metadata": {},
   "source": [
    "You can also use SQLite Caches: https://python.langchain.com/docs/modules/model_io/models/chat/how_to/chat_model_caching#sqlite-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e061d-c254-4e64-b81a-5dbd4f0cc59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
